## ToC
- [해의 표현 및 사용한 GA 전체 구조](#해의-표현-및-사용한-ga-전체-구조)
  - [해의 표현](#해의-표현)
  - [GA 구조](#ga-구조)
- [Dynamic programming을 활용한 방안](#dynamic-programming을-활용한-방안)
- [사용한 GA 연산자에 대한 설명과 DP 알고리즘 설명](#사용한-ga-연산자에-대한-설명과-dp-알고리즘-설명)
- [함께 제공하는 세 개의 샘플 인스턴스 인스턴스에 대해 GA를 각각 최소 30번씩 수행하여 가장 좋은 결과, 평균 결과, 표준편차를 테이블로 기록(최소 90번의 GA run)](#함께-제공하는-세-개의-샘플-인스턴스-인스턴스에-대해-ga를-각각-최소-30번씩-수행하여-가장-좋은-결과-평균-결과-표준편차를-테이블로-기록최소-90번의-ga-run)
- [시도해본 개선안](#시도해본-개선안)
- [Discussion(느낀 점, 잘 안 되는 점, 의외의 현상, 예상대로 된 점 등)](#discussion느낀-점-잘-안-되는-점-의외의-현상-예상대로-된-점-등)
  - [테스트 데이터 정답](#테스트-데이터-정답)

# 해의 표현 및 사용한 GA 전체 구조
## 해의 표현
A, B를 그래프 노드 수만큼 나열한 문자열로 표현. 문자열 인덱스와 노드 번호가 같고, 각 자리 글자가 노드가 속한 그룹을 의미함.
## GA 구조
1. 노드 수만큼 A, B를 50% 확률로 뽑아 해를 생성하고, 유효한 해인지 검사하며 cost를 계산하고 대륙을 부여해 부모 집합을 만든다.
2. 서로 같은 대륙끼리 교배한다. female이 cost 토너먼트로 먼저 뽑히고, female의 cost에 따라 male이 선택된다. 부모의 cost 차이가 서로 일정량 이하인 경우만 교배하도록 하며, 낮은 확률로 cost 차이가 큰 부모 쌍이 생성될 수 있고, 자식도 더 많이 생성한다. 자식은 생성 직후 돌연변이를 시도하며, 생성된 자식을 검사해 유효하지 않은 것은 바로 제거한다.
3. 일정 수의 부모 쌍을 선택하여 생성된 자식들은 자신보다 cost가 약간 작은 유전자를 대체한다. 대체할 유전자가 없는 경우 높은 확률로 제거된다.
4. 제한 시간 내에 대륙 내 진화가 수렴하면 지역 최적화를 잠깐 시도한 후 위와 같은 과정으로 대륙 통합 진화를 시작한다.
5. 진화 및 지역 최적화가 끝나거나 제한 시간이 다 되었을 때 최선의 해를 반환한다.

# Dynamic programming을 활용한 방안
* 지역 최적화를 할 때는 비슷한 해의 cost를 자주 계산하게 된다. 지역 최적화 내에서의 cost 계산에 대해 memo 벡터를 추가해 중복된 cost 계산을 줄였다. 이후 모든 해의 validation 과정에 memo를 사용해 전체적인 cost 계산 시간을 줄였다.
* 지역 최적화를 할 때 해를 한 자리 변경해도 cost가 유지되는 경우가 있다. 이때 바뀐 해를 이용해 최적화를 계속하는 게 더 나은지, 이전 해를 이용하는 게 더 나은지 두 가지 경우에 대해 모두 지역 최적화 함수를 다시 호출하고 결과가 더 좋은 해를 사용한다. 다만 재귀호출된 지역 최적화 함수 내에서도 다시 재귀호출을 하면 스택 오버플로우가 발생하여 재귀 호출은 한 번으로 제한된다. 이 방법을 사용하면 성능이 하락하여 지금은 폐기하였다.

# 사용한 GA 연산자에 대한 설명과 DP 알고리즘 설명
* validate: 해의 유효성을 검사함과 동시에 해의 cost를 계산한다. 계산한 모든 해의 cost는 map으로 저장하여 이후 재사용한다.
* selection: 전체 유전자 풀을 두 대륙으로 나누어, 서로 같은 대륙끼리 교배한다. 부모의 cost 차이를 일정 수치로 제한하나 낮은 확률로 제한되지 않은 쌍이 생성될 수 있다.
* crossover: 해의 각 자리를 60% 확률로 부모 중 우월한 쪽의 것으로 선택한다.
* mutation: 각 자리마다 일정 확률로 다시 선택하며, 이전의 값과 똑같을 수 있다. 평균 약 0.8% 발생.
* replacement: generational GA 방식 이용, cost가 약간 작은 것과 대체한다. 대체 실패한 해는 낮은 확률로 그대로 pool에 포함된다.
* local optimization: 현재 보유한 해 중 가장 좋은 것을 선택, 해의 각 자리를 랜덤한 순서로 flip하여 cost가 같거나 커지는 쪽으로 해를 바꾼다. 일정 횟수 이상 개선되지 않을 때까지 한다. validation 시간을 줄이기 위해 계산한 모든 해의 cost는 map에 저장되고 재사용된다.

# 함께 제공하는 세 개의 샘플 인스턴스 인스턴스에 대해 GA를 각각 최소 30번씩 수행하여 가장 좋은 결과, 평균 결과, 표준편차를 테이블로 기록(최소 90번의 GA run)


# 시도해본 개선안
* 지역 최적화를 추가하면서 다양한 방식으로 해의 품질을 높이려 해봤는데, 제한 시간이 있기 때문에 짧고 여러 번 실행되는 지역 최적화 보다는 길게 한번에 실행되는 지역 최적화가 훨씬 효과가 좋았다.
* 지난 과제 피드백에서, 세대 교체 과정을 좀 더 개선할 수 있을 것 같아 보인다는 말에 랜덤성을 줄이고 cost가 가장 나쁜 것부터 차례로 대체하게 만들어봤는데 오히려 결과 품질이 떨어졌다.
* 토너먼트 승률을 두 대상의 cost 차이에 비례하게 만들어봤는데, 해의 품질이 떨어져서 다시 고정수치로 바꿨다.
* 지역 최적화 중 변이 전후 cost가 동일한 경우에 대해 재귀 호출을 이용해 더 전망이 좋은 것을 선택하면 결과도 더 좋아질 줄 알았는데 의외로 결과의 평균이 떨어졌다.
* 초기 풀 크기가 100일 때 결과가 의외로 잘 나와서 50으로 줄여봤는데, 평균은 떨어지고 표준편차는 상승해서 다시 100으로 되돌렸다. 초기 풀이 클수록 결과가 잘 나오는 경향이 있는 건 맞는 것 같지만, 그래프의 크기가 클수록 수렴과 진화에 걸리는 시간이 길어져 시간 내에 충분한 결과를 내지 못해 100을 상한으로 잡기로 했다.
* 예를 들면 AABB와 BBAA처럼 뒤집으면 서로 같아지는 해를 배제하기 위해 모든 해의 첫 글자를 A로 고정하고 보호해봤는데, 가능한 해의 다양성이 절반으로 줄어서 그런지 성능이 떨어졌다.
* cost가 같은 해들의 공통된 부분을 모아 스키마로 삼고 교배 시 이 부분을 보호하게 해보려고 했는데, 막상 디버깅해보니 보호되는 글자 수는 지극히 적었고, cost는 있지만 스키마는 생성되지 않는 오류가 발생해 이 방안은 폐기했다.
* 토너먼트 참가자 수를 2의 거듭제곱으로 맞추려다보니 수를 정하는 코드가 복잡해져서 구현 방식을 큐로 바꿨다.
* 세대 교체 방식에서 랜덤성을 약간만 줄였다. 교체 대상 cost는 랜덤으로 뽑되 구체적인 교체 대상은 벡터의 맨 마지막 요소로 고정한다. cost가 다르면 유의미한 차이지만 cost가 같은 해끼리는 그다지 유의미하지 않은 차이라고 생각했다.
* 교배와 진화보다 지역 최적화로 개선되는 cost 변화량이 훨씬 큰 것 같아 지역 최적화에 시간을 많이 투자하게 했다. 그래프 크기가 클수록 pool은 작게 만들어 빠르게 진화하고 남은 시간은 모두 지역 최적화에 투자한다.
* 지역 최적화 Simulated Annealing 도입. 복잡도가 큰 그래프 데이터를 사용하면 결과 편차가 너무 크게 나오는 문제가 있었는데, 이 방법으로 편차가 약간 줄었다. 평균도 상승했다. 처음엔 cost가 나빠지면 온도를 감소시키기만 했는데, 그래도 수렴 속도가 너무 빠른 것 같아 cost가 같거나 좋아지면 약간 증가시키는 코드를 추가했고, 도움이 되었다. 이후엔 cost를 증가시키는 비율을 조정하면서 결과 편차를 줄이려고 했다.


# Discussion(느낀 점, 잘 안 되는 점, 의외의 현상, 예상대로 된 점 등)
* 대륙을 분리하여 따로 진화시켜 수렴한 후에 다시 섞어서 교배하면 좀 좋은 해가 나올까 했는데 순수 GA와 크게 다르지 않아 약간 실망했다. 뭐가 문제인지는 잘 모르겠지만, 지역 최적화가 해의 품질을 상당히 높여서 다행이었다.
* 지난 과제부터 비주얼 스튜디오의 빠른 실행을 위해 Release 상태로 실행을 해왔는데, 이 경우 실행 도중 오류가 나서 중단되었을 때 오류를 보여주지 않고 꺼진다는 것을 알게 되었다. 디버깅 모드가 따로 존재하는 이유가 있었다.
* 돌연변이가 구현만 되어 있고 사용되지 않고 있었다. 확인 즉시 수정했다.
* 여러 가지 하이퍼 파라미터들을 그래프 크기에 비례하는 랜덤 숫자로 해보니까, 랜덤성이 과하면 오히려 품질이 떨어지는 것 같다.
* 지역 최적화에 시간을 많이 투자하는 게 좋다고 생각해 여러 자잘한 과정에서 시간을 줄이려는 고민을 많이 했다.